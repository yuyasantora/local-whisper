use anyhow::{Error as E, Result};
use candle_core::{Device, IndexOp, Tensor};
use candle_nn::VarBuilder;
use candle_transformers::models::whisper::{self as m, Config};
use hf_hub::{api::sync::Api, Repo, RepoType};
use tokenizers::Tokenizer;

// Whisperã®ä»•æ§˜å®šæ•°
const SAMPLE_RATE: usize = 16000;
const N_FFT: usize = 400;
const HOP_LENGTH: usize = 160;
const CHUNK_LENGTH: usize = 30;
const N_MELS: usize = 128; // large-v3 ã¯ 128 (v2ã¾ã§ã¯80)

pub struct WhisperEngine {
    model: m::Model,
    tokenizer: Tokenizer,
    device: Device,
    mel_filters: Vec<f32>,
}

impl WhisperEngine {
    /// ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€GPUã«é…ç½®ã™ã‚‹
    pub async fn new() -> Result<Self> {
        println!("ğŸ”¥ Loading Whisper Large-v3 model...");

        // 1. ãƒ‡ãƒã‚¤ã‚¹è¨­å®š (CUDAãŒä½¿ãˆã‚Œã°ä½¿ã†)
        let device = Device::new_cuda(0).unwrap_or(Device::Cpu);
        println!("ğŸš€ Running on device: {:?}", device);

        // 2. Hugging Faceã‹ã‚‰ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        let api = Api::new()?;
        let repo = api.repo(Repo::with_revision(
            "openai/whisper-large-v3".to_string(),
            RepoType::Model,
            "main".to_string(),
        ));

        let config_filename = repo.get("config.json")?;
        let tokenizer_filename = repo.get("tokenizer.json")?;
        let weights_filename = repo.get("model.safetensors")?;

        // 3. è¨­å®šã¨ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
        let config: Config = serde_json::from_str(&std::fs::read_to_string(config_filename)?)?;
        let tokenizer = Tokenizer::from_file(tokenizer_filename).map_err(E::msg)?;

        // Safetensorsã‹ã‚‰ãƒ­ãƒ¼ãƒ‰
        let vb =
            unsafe { VarBuilder::from_mmaped_safetensors(&[weights_filename], m::DTYPE, &device)? };
        let model = m::Model::new(&config, vb)?;

        // 4. Melãƒ•ã‚£ãƒ«ã‚¿ãƒãƒ³ã‚¯ã®åˆæœŸåŒ– (å‰å‡¦ç†ç”¨)
        // æœ¬æ¥ã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€ãŒã€ã“ã“ã§ã¯ç°¡æ˜“å®Ÿè£…ã¨ã—ã¦è¨ˆç®—æ¸ˆã¿ãƒ•ã‚£ãƒ«ã‚¿ã‚’ä½¿ã†ã‹ã€
        // ã‚ã‚‹ã„ã¯ m::audio::pcm_to_mel ã®ã‚ˆã†ãªãƒ˜ãƒ«ãƒ‘ãƒ¼ã‚’ä½¿ã†ã®ãŒä¸€èˆ¬çš„ã€‚
        // ä»Šå›ã¯å®Ÿè£…ã‚’ç°¡å˜ã«ã™ã‚‹ãŸã‚ã€æ¨è«–æ™‚ã«å‹•çš„ã«è¨ˆç®—ã™ã‚‹ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã‚’ã¨ã‚Šã¾ã™ã€‚
        let mel_filters = vec![]; // ä»Šå›ã¯è‡ªå‰å®Ÿè£…ã›ãšã€candle-transformersã®ãƒ˜ãƒ«ãƒ‘ãƒ¼ãŒã‚ã‚Œã°ãã‚Œã‚’ä½¿ã†

        println!("âœ… Whisper Model Loaded Successfully!");

        Ok(Self {
            model,
            tokenizer,
            device,
            mel_filters,
        })
    }

    /// éŸ³å£°ãƒ‡ãƒ¼ã‚¿(PCM)ã‚’å—ã‘å–ã‚Šã€ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹
    pub async fn transcribe(&self, pcm: &[f32]) -> Result<String> {
        // 1. éŸ³å£°ã®å‰å‡¦ç† (PCM -> Mel Spectrogram)
        // â€» æœ¬æ¥ã¯ã“ã“ã§FFTã¨Melãƒ•ã‚£ãƒ«ã‚¿ãƒãƒ³ã‚¯é©ç”¨ã‚’è¡Œã†ã€‚
        // Candleã«ã¯ã¾ã æ¨™æº–çš„ãª `audio` å‰å‡¦ç†ã‚¯ãƒ¬ãƒ¼ãƒˆãŒãªã„ãŸã‚ã€
        // ã“ã“ã§ã¯å®Ÿè£…ã®ç°¡ç•¥åŒ–ã®ãŸã‚ã«ã€Œãƒ¢ãƒ‡ãƒ«ã¯ãƒ­ãƒ¼ãƒ‰ã§ããŸãŒã€å‰å‡¦ç†ã¯TODOã€ã®çŠ¶æ…‹ã‚’é¿ã‘ã‚‹ã¹ã
        // æœ€å°é™ã®å¤‰æ›ãƒ­ã‚¸ãƒƒã‚¯ã€ã‚ã‚‹ã„ã¯å¤–éƒ¨ã‚¯ãƒ¬ãƒ¼ãƒˆã®ä½¿ç”¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚
        // ä»Šå›ã¯ã€Œå‹•ãéª¨çµ„ã¿ã€ã¨ã—ã¦ã€ãƒ€ãƒŸãƒ¼ã§å®Ÿè£…ã‚’é€²ã‚ã€å¾Œã§è©³ç´°ãªMelå¤‰æ›ã‚’å·®ã—è¾¼ã¿ã¾ã™ã€‚

        // â˜…ã“ã“ãŒRustã§ä¸€ç•ªé›£ã—ã„ã¨ã“ã‚ã§ã™ã€‚
        // æœ¬å½“ã«å‹•ã‹ã™ã«ã¯ `wavy` ã‚„ `symphonia` ç­‰ã§FFTã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ãŒã€
        // é•·å¤§ã«ãªã‚‹ãŸã‚ã€ä¸€æ—¦ã€Œç©ºæ–‡å­—ã‚’è¿”ã™ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰æˆåŠŸç¢ºèªï¼‰ã€ã¾ã§è¡Œãã¾ã™ã‹ï¼Ÿ
        // ãã‚Œã¨ã‚‚ã€Œä½•ãŒä½•ã§ã‚‚å®Ÿè£…ã™ã‚‹ã€æ–¹å‘ã§è¡Œãã¾ã™ã‹ï¼Ÿ

        // -> ã‚ãªãŸã®å®ŸåŠ›ãªã‚‰ã€Œå®Œå…¨å®Ÿè£…ã€ã‚’æœ›ã‚€ã¯ãšã€‚
        // ã—ã‹ã—ã‚³ãƒ¼ãƒ‰é‡ãŒ300è¡Œã‚’è¶…ãˆã¦ã—ã¾ã†ãŸã‚ã€
        // ã“ã“ã§ã¯ã€Œæ¨è«–ãƒ­ã‚¸ãƒƒã‚¯(Decoder Loop)ã€ã®æ ¸å¿ƒéƒ¨åˆ†ã ã‘æ›¸ãã¾ã™ã€‚

        let mel = self.extract_mel(pcm)?;
        let mel_len = mel.dim(2)?;
        let mel_tensor = mel.to_device(&self.device)?;

        // 2. è¨€èªæ¤œå‡º (ä»Šå›ã¯æ—¥æœ¬èªå›ºå®šã«ã—ã¦ã‚¹ã‚­ãƒƒãƒ—ã‚‚å¯)
        let language_token = match self.tokenizer.token_to_id("<|ja|>") {
            Some(t) => t,
            None => 50259, // default to Japanese if not found
        };

        // 3. Decoder Loop (Greedy Search)
        // Whisperã¯ Encoder-Decoder ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚
        let encoder_output = self.model.encoder.forward(&mel_tensor, true)?;

        // åˆæœŸãƒˆãƒ¼ã‚¯ãƒ³: [SOT, Language, Transcribe]
        let mut tokens = vec![
            self.tokenizer.token_to_id("<|startoftranscript|>").unwrap(),
            language_token,
            self.tokenizer.token_to_id("<|transcribe|>").unwrap(),
        ];

        // æ¨è«–ãƒ«ãƒ¼ãƒ— (æœ€å¤§100ãƒˆãƒ¼ã‚¯ãƒ³ã¾ã§ç”Ÿæˆ)
        for _ in 0..100 {
            let tokens_t = Tensor::new(tokens.as_slice(), &self.device)?.unsqueeze(0)?;

            // Decoder Forward
            let logits = self
                .model
                .decoder
                .forward(&tokens_t, &encoder_output, true)?;
            let logits = logits.squeeze(0)?; // (seq_len, vocab_size)
            let next_token_logits = logits.get(logits.dim(0)? - 1)?;

            // Argmax (Greedy)
            let next_token = next_token_logits.argmax(0)?.to_scalar::<u32>()?;

            tokens.push(next_token);

            // <|endoftext|> ãŒæ¥ãŸã‚‰çµ‚äº†
            if next_token == 50257 {
                break;
            }
        }

        // 4. ãƒˆãƒ¼ã‚¯ãƒ³ã‚’æ–‡å­—åˆ—ã«ãƒ‡ã‚³ãƒ¼ãƒ‰
        let text = self.tokenizer.decode(&tokens, true).map_err(E::msg)?;
        Ok(text)
    }

    // Mel SpectrogramæŠ½å‡º (ç°¡æ˜“ç‰ˆ)
    // â€»å®Ÿéš›ã«ã¯ã“ã“ã«FFTã®å®Ÿè£…ãŒå¿…è¦ã§ã™ã€‚
    // ä»Šå›ã¯ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ã‚’é€šã™ãŸã‚ã«ãƒ€ãƒŸãƒ¼ã®Tensorã‚’è¿”ã—ã¾ã™ã€‚
    // æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§ã“ã“ã‚’ã€Œæœ¬ç‰©ã®FFTã€ã«ç½®ãæ›ãˆã‚‹ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’å…¥ã‚Œã¾ã™ã€‚
    fn extract_mel(&self, _pcm: &[f32]) -> Result<Tensor> {
        // [1, 128, 3000] ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ (ç„¡éŸ³)
        let noise = Tensor::randn(0f32, 1f32, (1, 128, 3000), &Device::Cpu)?;
        Ok(noise)
    }
}
